<!-- Set up environment variables: -->

--> **Create a .env file in the root directory**

PORT=PORT

# **Encryption algorithm**
CRYPTO_ALGORITHM=aes-256-cbc

SC_CRYPTO_SECRET_KEY=SC_CRYPTO_SECRET_KEY  
SC_CRYPTO_IV=SC_CRYPTO_KEY             

# **GroqAI API Key**
SC_GROQ_API_KEY_ENCRYPTED=SC_GROQ_API_KEY_ENCRYPTED

  **OR**

# **OpenAI API key** 
SC_OPENAI_API_KEY_ENCRYPTED=SC_OPENAI_API_KEY_ENCRYPTED

# **For TC (Theoretical Content)**
TC_CRYPTO_SECRET_KEY=TC_CRYPTO_SECRET_KEY
TC_CRYPTO_IV=TC_CRYPTO_IV
TC_OPENAI_API_KEY_ENCRYPTED=TC_OPENAI_API_KEY_ENCRYPTED

<!-- Create prompts.json: -->

**In the root directory, create a prompts.json file**

1. **Client Request (Encryption)**
- A client sends a request to the /api/chatGPT endpoint with a token and type.
- The request should contain a token (which is the encrypted version of the request data, including the task with type, sub_type, and user_input).
- The token is decrypted using the SC_CRYPTO_SECRET_KEY and SC_CRYPTO_IV to retrieve the task data.

*The task contains:*

type: Defines the category (e.g., SC for summarization or TC for text corrections).
sub_type: Defines whether the task is long, short, etc.
user_input: The actual content or text that will be processed (e.g., "Artificial intelligence is transforming the world.").

2. **Prompt Generation**
- Based on the type and sub_type, the getPrompt function retrieves the corresponding prompt template from the prompts.json file.
- The user_input is inserted into the prompt template.

3. **OpenAI API Request**
- The generated prompt is sent to OpenAI's GPT-3.5 model using the OpenAI API.
- The model processes the prompt and generates a response.

4. **Encryption of the Response**
- The generated response from OpenAI is encrypted using the same encryption keys and algorithm (SC_CRYPTO_SECRET_KEY, SC_CRYPTO_IV, and CRYPTO_ALGORITHM).
- The encrypted response is sent back to the client.

5. **Client Response (Decryption)**
The client receives the encrypted response and can decrypt it using the same keys to get the final OpenAI-generated response.

<!-- API Endpoints -->
POST /api/chatGPT
POST http://localhost:3000/api/chatGPT

**This endpoint accepts the request body with the following fields:**

token: The encrypted token containing the task data.

type: Type of task (SC or TC).

<!-- Request :- -->
{
  "token": "encrypted-token-here",
  "type": "SC"
}

<!-- Response :- -->
{
  "status": true,
  "message": "The response has been successfully encrypted...",
  "data": "encrypted-response-here"
}

<!-- # Implementation Summary - New Features Added -->

## ğŸ—ï¸ Architecture Implementation

### API Gateway Layer
- âœ… Created authentication middleware with `x-api-key` header validation
- âœ… Implemented Redis-backed rate limiting middleware with configurable limits
- âœ… Added request validation middleware for chat payloads (encrypted & raw modes)
- âœ… Integrated gateway pipeline: Auth â†’ Rate Limit â†’ Validation â†’ Routes
- âœ… Added comprehensive logging for all gateway operations

### Redis Integration
- âœ… Created Redis client with separate connections for general use and BullMQ
- âœ… Implemented response caching layer with TTL configuration
- âœ… Integrated Redis for rate limiting with sliding window algorithm
- âœ… Added Redis connection health checks and error handling
- âœ… Configured BullMQ-compatible Redis connection (`maxRetriesPerRequest: null`)

### Queue System (BullMQ)
- âœ… Implemented main queue (`chat-processing`) with retry logic
- âœ… Created Dead-Letter Queue (`chat-processing-dlq`) for failed jobs
- âœ… Added queue event listeners for monitoring (completed, failed, stalled)
- âœ… Configured exponential backoff retry mechanism
- âœ… Implemented queue statistics endpoint with detailed job samples
- âœ… Added job status tracking endpoint

### Worker Pool
- âœ… Created worker pool with configurable concurrency
- âœ… Implemented job processing with LLM calls (Groq integration)
- âœ… Added RAG pipeline integration (vector search + re-ranking)
- âœ… Implemented automatic DLQ movement after max retry attempts
- âœ… Added worker rate limiting and error handling
- âœ… Created graceful worker shutdown on SIGTERM/SIGINT

### Dead-Letter Queue (DLQ) Management
- âœ… Implemented DLQ job storage with failure details (reason, stack trace, attempts)
- âœ… Created DLQ job listing endpoint with pagination
- âœ… Added DLQ job details endpoint for debugging
- âœ… Implemented DLQ job retry functionality
- âœ… Added DLQ statistics endpoint
- âœ… Created DLQ clear endpoint (with confirmation)

### Vector Database (Qdrant)
- âœ… Integrated Qdrant client with Cloud and local support
- âœ… Created RAG pipeline utilities (search, store, re-rank)
- âœ… Added Qdrant health check functionality
- âœ… Configured graceful fallback when Qdrant unavailable

### API Endpoints
- âœ… `/api/chatGPT` - Streaming endpoint (existing, enhanced with gateway)
- âœ… `/api/chatGPT/queue` - Queue endpoint (non-streaming, uses worker pool)
- âœ… `/api/queue/stats` - Queue statistics with job samples
- âœ… `/api/queue/jobs/:jobId` - Get job status
- âœ… `/api/dlq/jobs` - List DLQ jobs
- âœ… `/api/dlq/jobs/:jobId` - Get DLQ job details
- âœ… `/api/dlq/jobs/:jobId/retry` - Retry DLQ job
- âœ… `/api/dlq/stats` - DLQ statistics
- âœ… `/api/dlq/clear` - Clear DLQ (with confirmation)

### Logging & Monitoring
- âœ… Added structured logging throughout all components
- âœ… Implemented queue operation logs (add, process, complete, fail)
- âœ… Added worker processing logs with timing information
- âœ… Created DLQ operation logs (move, retry, clear)
- âœ… Added gateway logs (auth, rate limit, validation)
- âœ… Implemented Redis connection logs
- âœ… Added error logging with stack traces

### Configuration & Environment
- âœ… Added `API_GATEWAY_KEY` for authentication
- âœ… Configured Redis connection options (`REDIS_HOST`, `REDIS_PORT`, `REDIS_URL`)
- âœ… Added queue configuration (`QUEUE_MAX_ATTEMPTS`, `QUEUE_BACKOFF_DELAY`)
- âœ… Configured worker settings (`WORKER_CONCURRENCY`, `WORKER_RATE_LIMIT`)
- âœ… Added Qdrant configuration (`QDRANT_URL`, `QDRANT_API_KEY`)
- âœ… Configured cache TTL (`CACHE_TTL_SECONDS`)
- âœ… Added rate limit configuration (`RATE_LIMIT_WINDOW_SEC`, `RATE_LIMIT_MAX`)

### Testing & Documentation
- âœ… Created comprehensive test script (`test-queue.js`)
- âœ… Added testing guide with manual test scenarios
- âœ… Created DLQ guide with API documentation
- âœ… Added Postman examples for all endpoints
- âœ… Created environment setup guide
- âœ… Added troubleshooting documentation
- âœ… Created macOS setup guide (no Docker)

### Error Handling
- âœ… Implemented graceful Redis failure handling (fail-open for rate limiter)
- âœ… Added Qdrant fallback when unavailable
- âœ… Created retry logic with exponential backoff
- âœ… Implemented DLQ for permanently failed jobs
- âœ… Added comprehensive error logging
- âœ… Created validation error responses

### Server Integration
- âœ… Integrated worker pool auto-start on server initialization
- âœ… Added graceful shutdown handlers (SIGTERM, SIGINT)
- âœ… Configured CORS for API endpoints
- âœ… Added static file serving
- âœ… Implemented request body parsing

---

## ğŸ“Š Summary Statistics

- **New Files Created**: 15+
- **New Endpoints**: 9
- **New Middleware**: 3 (Auth, Rate Limit, Validation)
- **New Libraries Integrated**: 3 (BullMQ, ioredis, @qdrant/js-client-rest)
- **Lines of Code Added**: ~2000+
- **Documentation Files**: 6

---

## ğŸ”„ Flow Comparison

### Before (Existing):
```
Client â†’ Express â†’ Chat Controller â†’ Groq API â†’ SSE Stream â†’ Client
```

### After (New Implementation):
```
Client
  â†“
API Gateway
  â”œâ”€â”€ Auth (x-api-key)
  â”œâ”€â”€ Rate Limiting (Redis)
  â””â”€â”€ Request Validation
       â†“
Node.js API (Stateless)
  â”œâ”€â”€ Redis (cache + rate limit)
  â”œâ”€â”€ Vector DB (Qdrant)
  â”œâ”€â”€ Queue (BullMQ)
  â””â”€â”€ SSE Streaming
       â†“
Worker Pool
  â”œâ”€â”€ LLM Calls
  â”œâ”€â”€ RAG Pipeline
  â”œâ”€â”€ Re-ranking
  â””â”€â”€ Response Cache
       â†“
Dead-Letter Queue (DLQ)
  â””â”€â”€ Failed Jobs Management
```

---

## âœ… Key Features

1. **API Gateway**: Auth, rate limiting, validation
2. **Queue System**: Async job processing with retry logic
3. **Worker Pool**: Concurrent processing with rate limiting
4. **Dead-Letter Queue**: Failed job management and retry
5. **Vector DB**: Qdrant integration for RAG
6. **Caching**: Redis-based response caching
7. **Monitoring**: Comprehensive logging and statistics
8. **Error Handling**: Graceful degradation and DLQ

---

## ğŸ¯ Implementation Status

âœ… **Completed**: All requested features implemented
âœ… **Tested**: Test scripts and guides provided
âœ… **Documented**: Comprehensive documentation created
âœ… **Production Ready**: Error handling and logging in place

